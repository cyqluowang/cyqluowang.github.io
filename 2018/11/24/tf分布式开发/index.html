<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.8.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>weiboSDK登入 | 无醉</title><link rel="stylesheet" type="text/css" href="/css/normalize.css"><link rel="stylesheet" type="text/css" href="/css/pure-min.css"><link rel="stylesheet" type="text/css" href="/css/grids-responsive-min.css"><link rel="stylesheet" type="text/css" href="/css/style.css"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">weiboSDK登入</h1><a id="logo" href="/">无醉</a><p class="description">所过之处皆成岚</p></div><div id="nav-menu"><a href="/" class="current"><i class="icon-home"> 首页</i></a><a href="/archives/"><i class="icon-archive"> 归档</i></a><a href="/about/"><i class="icon-about"> 关于</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post post-page"><h1 class="post-title">weiboSDK登入</h1><div class="post-meta">2018-11-24 | </div><span data-thread-key="2018/11/24/tf分布式开发/" class="ds-thread-count"></span><div class="post-content"><p> 在大数据的情况下，基于单机的建模已经不能满足现有的需求了，所以需要在集群上进行建模，这个时候需要使用分布式的开发方式。单机和分布式的开发代码是有所区别的，这里就简单介绍下tensoflow的分布式开发的两种方式</p>
<h1 id="基于tf原生的分布式开发"><a href="#基于tf原生的分布式开发" class="headerlink" title="基于tf原生的分布式开发"></a>基于tf原生的分布式开发</h1><h4 id="1、分布式的话就会涉及到更新梯度的方式，有同步和异步的两个方案，同步更新的方式在模型的表现上能更快的进行收敛，异步更新迭代的速度会更加快。两种更新方式入下图："><a href="#1、分布式的话就会涉及到更新梯度的方式，有同步和异步的两个方案，同步更新的方式在模型的表现上能更快的进行收敛，异步更新迭代的速度会更加快。两种更新方式入下图：" class="headerlink" title="1、分布式的话就会涉及到更新梯度的方式，有同步和异步的两个方案，同步更新的方式在模型的表现上能更快的进行收敛，异步更新迭代的速度会更加快。两种更新方式入下图："></a>1、分布式的话就会涉及到更新梯度的方式，有同步和异步的两个方案，同步更新的方式在模型的表现上能更快的进行收敛，异步更新迭代的速度会更加快。两种更新方式入下图：</h4><p><img src="https://upload-images.jianshu.io/upload_images/295077-12bc552516617deb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/500" alt="image.png"></p>
<p><img src="https://upload-images.jianshu.io/upload_images/295077-9cd8c251289eb4d7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/500" alt="image.png"></p>
<h4 id="2、-tf是基于ps，-work-两种服务器进行分布式的开发。ps服务器可以只用与参数的汇总更新，让各个work进行梯度的计算。"><a href="#2、-tf是基于ps，-work-两种服务器进行分布式的开发。ps服务器可以只用与参数的汇总更新，让各个work进行梯度的计算。" class="headerlink" title="2、 tf是基于ps， work 两种服务器进行分布式的开发。ps服务器可以只用与参数的汇总更新，让各个work进行梯度的计算。"></a>2、 tf是基于ps， work 两种服务器进行分布式的开发。ps服务器可以只用与参数的汇总更新，让各个work进行梯度的计算。</h4><h4 id="3、具体开发流程："><a href="#3、具体开发流程：" class="headerlink" title="3、具体开发流程："></a>3、具体开发流程：</h4><p>首先指定ps 服务器启动参数 –job_name=ps<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python distribute.py --ps_hosts=<span class="number">192.168</span><span class="number">.100</span><span class="number">.42</span>:<span class="number">2222</span> --worker_hosts=<span class="number">192.168</span><span class="number">.100</span><span class="number">.42</span>:<span class="number">2224</span>,<span class="number">192.168</span><span class="number">.100</span><span class="number">.253</span>:<span class="number">2225</span> --job_name=ps --task_index=<span class="number">0</span></span><br></pre></td></tr></table></figure></p>
<p>接着指定work服务器参数(启动两个work 节点) –job_name=worker<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">python distribute.py --ps_hosts=<span class="number">192.168</span><span class="number">.100</span><span class="number">.42</span>:<span class="number">2222</span> --worker_hosts=<span class="number">192.168</span><span class="number">.100</span><span class="number">.42</span>:<span class="number">2224</span>,<span class="number">192.168</span><span class="number">.100</span><span class="number">.253</span>:<span class="number">2225</span> --job_name=worker --task_index=<span class="number">0</span></span><br><span class="line">python distribute.py --ps_hosts=<span class="number">192.168</span><span class="number">.100</span><span class="number">.42</span>:<span class="number">2222</span> --worker_hosts=<span class="number">192.168</span><span class="number">.100</span><span class="number">.42</span>:<span class="number">2224</span>,<span class="number">192.168</span><span class="number">.100</span><span class="number">.253</span>:<span class="number">2225</span> --job_name=worker --task_index=<span class="number">1</span></span><br></pre></td></tr></table></figure></p>
<p>上面指定的参数 worker_hosts ps_hosts job_name task_index 都会在py文件中接受使用</p>
<p>参数接收使用<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.app.flags.DEFINE_string(<span class="string">"worker_hosts"</span>, <span class="string">"默认值"</span>, <span class="string">"描述说明"</span>)</span><br></pre></td></tr></table></figure></p>
<p>接收了参数后分别注册ps work，让他们各司其职。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">ps_hosts = FLAGS.ps_hosts.split(<span class="string">","</span>)</span><br><span class="line">worker_hosts = FLAGS.worker_hosts.split(<span class="string">","</span>)</span><br><span class="line">cluster = tf.train.ClusterSpec(&#123;<span class="string">"ps"</span>: ps_hosts, <span class="string">"worker"</span>: worker_hosts&#125;)</span><br><span class="line">server = tf.train.Server(cluster,job_name=FLAGS.job_name,task_index=FLAGS.task_index)</span><br><span class="line"></span><br><span class="line">issync = FLAGS.issync</span><br><span class="line"><span class="keyword">if</span> FLAGS.job_name == <span class="string">"ps"</span>:</span><br><span class="line">    server.join()</span><br><span class="line"><span class="keyword">elif</span> FLAGS.job_name == <span class="string">"worker"</span>:</span><br><span class="line">    <span class="keyword">with</span> tf.device(tf.train.replica_device_setter(</span><br><span class="line">                    worker_device=<span class="string">"/job:worker/task:%d"</span> % FLAGS.task_index,</span><br><span class="line">                    cluster=cluster)):</span><br></pre></td></tr></table></figure></p>
<p>接下来更新梯度：<br>同步<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">rep_op = tf.train.SyncReplicasOptimizer(optimizer,</span><br><span class="line">                                                replicas_to_aggregate=len(worker_hosts),</span><br><span class="line">                                                replica_id=FLAGS.task_index,</span><br><span class="line">                                                total_num_replicas=len(worker_hosts),</span><br><span class="line">                                                use_locking=<span class="keyword">True</span>)</span><br><span class="line">train_op = rep_op.apply_gradients(grads_and_vars,global_step=global_step)</span><br><span class="line">init_token_op = rep_op.get_init_tokens_op()</span><br><span class="line">chief_queue_runner = rep_op.get_chief_queue_runner()</span><br></pre></td></tr></table></figure></p>
<p>异步更新梯度：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_op = optimizer.apply_gradients(grads_and_vars,global_step=global_step)</span><br></pre></td></tr></table></figure></p>
<p>使用tf.train.Supervisor 进行真的迭代<br>注意：如果是同步更新梯度要加入<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sv.start_queue_runners(sess, [chief_queue_runner])</span><br><span class="line">sess.run(init_token_op)</span><br></pre></td></tr></table></figure></p>
<p>这个异步的方式虽然能够使用，但是有点麻烦，要自己指定集群集群ip和端口，但是我们往往自己不知道这些信息，所以这个时候可以借助 TensorFlowOnSpark来解决，使用yarn来管理。</p>
<h1 id="基于TensorFlowOnSpark的分布式开发"><a href="#基于TensorFlowOnSpark的分布式开发" class="headerlink" title="基于TensorFlowOnSpark的分布式开发"></a>基于TensorFlowOnSpark的分布式开发</h1><p>使用spark-submit  来提交任务同时指定spark需要运行的参数（–num-executors 6等），模型代码，模型超参等<br>这边同样需要接受外部参数<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">"-i"</span>, <span class="string">"--tracks"</span>, help=<span class="string">"数据集路径"</span>)  </span><br><span class="line">args = parser.parse_args()</span><br></pre></td></tr></table></figure></p>
<p>参数准备好，训练数据（DataFrame）准备好，调用模型的api进行启动<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">estimator = TFEstimator(soft_dist.map_fun, args) \</span><br><span class="line">      .setInputMapping(&#123;<span class="string">'tracks'</span>: <span class="string">'tracks'</span>, <span class="string">'label'</span>: <span class="string">'label'</span>&#125;) \</span><br><span class="line">      .setModelDir(args.model) \</span><br><span class="line">      .setExportDir(args.serving) \</span><br><span class="line">      .setClusterSize(args.cluster_size) \</span><br><span class="line">      .setNumPS(num_ps) \</span><br><span class="line">      .setEpochs(args.epochs) \</span><br><span class="line">      .setBatchSize(args.batch_size) \</span><br><span class="line">      .setSteps(args.max_steps)</span><br><span class="line">    model = estimator.fit(df)</span><br></pre></td></tr></table></figure></p>
<p>soft_dist.map_fun 要调起的方法，后面都是模型训练的参数</p>
<p>soft_dist定义一个 map_fun(args, ctx)的方法<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">map_fun</span><span class="params">(args, ctx)</span>:</span></span><br><span class="line">...</span><br><span class="line">worker_num = ctx.worker_num  <span class="comment"># worker数量</span></span><br><span class="line">job_name = ctx.job_name  <span class="comment"># job名</span></span><br><span class="line">task_index = ctx.task_index  <span class="comment"># 任务索引</span></span><br><span class="line"><span class="keyword">if</span> job_name == <span class="string">"ps"</span>:  <span class="comment"># ps节点(主节点)</span></span><br><span class="line">   time.sleep((worker_num + <span class="number">1</span>) * <span class="number">5</span>)</span><br><span class="line">   cluster, server = TFNode.start_cluster_server(ctx, <span class="number">1</span>, args.rdma)</span><br><span class="line">   num_workers = len(cluster.as_dict()[<span class="string">'worker'</span>])</span><br><span class="line">   <span class="keyword">if</span> job_name == <span class="string">"ps"</span>:</span><br><span class="line">        server.join()</span><br><span class="line">   <span class="keyword">elif</span> job_name == <span class="string">"worker"</span>:</span><br><span class="line">        <span class="keyword">with</span> tf.device(tf.train.replica_device_setter(worker_device=<span class="string">"/job:worker/task:%d"</span> % task_index, cluster=cluster)):</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<p>后面使用tf.train.MonitoredTrainingSession高级api 进行模型训练和预测。<br>这里可以有点小技巧，在模型结束的时候，可以发送邮件通知自己。这样可以及时的知道明星运行的情况。</p>
<p><strong><em>注意，如果是用SessionRunHook来保存最后输出的模型，要了解框架代码是有个bug 的，他只能在规定的时间内保存完，没有运行结束也会被kill，如果你的版本不是bug修复后的，要自己处理，放宽运行时间。</em></strong></p>
<p>tf分布式的开发大致是这两种情况，后边的方式可以用于实际的生产环境，还是比较稳定的。这边提供一个大体的思路和注意点，希望对大家有所帮助。最好的开发指南还是在官方的文档。</p>
</div><div class="tags"><a href="/tags/tensorflow/">tensorflow</a></div><div class="post-nav"><a href="/2018/11/24/tensorflow分布式开发/" class="pre"><i class="icon-previous">tensorflow分布式开发</i></a><a href="/2017/08/23/浏览器打印IOS日志/" class="next">浏览器打印iOS日志<i class="icon-next"></i></a></div><div data-thread-key="2018/11/24/tf分布式开发/" data-title="weiboSDK登入" data-url="http://cyqluowang.github.io/2018/11/24/tf分布式开发/" class="ds-share flat"><div class="ds-share-inline"><ul class="ds-share-icons-16"><li data-toggle="ds-share-icons-more"><a href="javascript:void(0);" class="ds-more">分享到：</a></li><li><a href="javascript:void(0);" data-service="weibo" class="ds-weibo">微博</a></li><li><a href="javascript:void(0);" data-service="qzone" class="ds-qzone">QQ空间</a></li><li><a href="javascript:void(0);" data-service="qqt" class="ds-qqt">腾讯微博</a></li><li><a href="javascript:void(0);" data-service="wechat" class="ds-wechat">微信</a></li></ul><div class="ds-share-icons-more"></div></div></div><div data-thread-key="2018/11/24/tf分布式开发/" data-title="weiboSDK登入" data-url="http://cyqluowang.github.io/2018/11/24/tf分布式开发/" data-author-key="1" class="ds-thread"></div></div></div></div><div class="pure-u-1-4"><div id="sidebar"><div class="widget"><form action="//www.baidu.com/baidu" method="get" accept-charset="utf-8" target="_blank" class="search-form"><input type="search" name="word" maxlength="20" placeholder="Search" class="search-form-input"><input type="hidden" name="si" value="http://cyqluowang.github.io"><input name="tn" type="hidden" value="bds"><input name="cl" type="hidden" value="3"><input name="ct" type="hidden" value="2097152"><input name="s" type="hidden" value="on"></form></div><div class="widget"><div class="widget-title">分类</div></div><div class="widget"><div class="widget-title">标签</div><div class="tagcloud"><a href="/tags/管理学/" style="font-size: 15px;">管理学</a> <a href="/tags/总结/" style="font-size: 15px;">总结</a> <a href="/tags/Carthage/" style="font-size: 15px;">Carthage</a> <a href="/tags/CocoaPods/" style="font-size: 15px;">CocoaPods</a> <a href="/tags/spring/" style="font-size: 15px;">spring</a> <a href="/tags/IOS/" style="font-size: 15px;">IOS</a> <a href="/tags/Android/" style="font-size: 15px;">Android</a> <a href="/tags/git/" style="font-size: 15px;">git</a> <a href="/tags/技巧/" style="font-size: 15px;">技巧</a> <a href="/tags/Mac/" style="font-size: 15px;">Mac</a> <a href="/tags/tensorflow/" style="font-size: 15px;">tensorflow</a> <a href="/tags/iOS/" style="font-size: 15px;">iOS</a> <a href="/tags/汽车/" style="font-size: 15px;">汽车</a></div></div><div class="widget"><div class="widget-title">最新文章</div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/11/24/tensorflow分布式开发/">tensorflow分布式开发</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/24/tf分布式开发/">weiboSDK登入</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/08/23/浏览器打印IOS日志/">浏览器打印iOS日志</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/08/22/Carthage/">项目支持Carthage</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/08/11/Pod使用subspec来代码模块化/">CocoaPods使用subspec来代码模块化</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/08/09/CocoaPods创建私有Pods/">CocoaPods创建私有Pods</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/08/09/pod 使用本地文件以及多级依赖/">CocoaPods本地多级依赖</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/08/09/pcocoapods 打包/">CocoaPods打包</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/03/08/AIDL/">AIDL</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/02/27/自定义控件/">自定义控件</a></li></ul></div><div class="widget"><div class="comments-title">最近评论</div><div data-num-items="5" data-show-avatars="0" data-show-time="1" data-show-admin="0" data-excerpt-length="32" data-show-title="1" class="ds-recent-comments"></div></div><div class="widget"><div class="widget-title">友情链接</div><ul></ul><a href="http://www.getui.com/" title="个推" target="_blank">个推</a><ul></ul><a href="http://www.19lou.com/" title="19lou" target="_blank">19lou</a><ul></ul><a href="http://www.renrunkeji.com/" title="仁润科技" target="_blank">仁润科技</a><ul></ul><a href="https://www.haomwei.com/technology/maupassant-hexo.html" title="maupassant使用" target="_blank">maupassant使用</a></div></div></div></div><div id="footer">© <a href="/" rel="nofollow">无醉.</a> QQ:573700261.</div><a id="rocket" href="#top" class="show"></a><script src="/js/jquery.min.js"></script>
<script src="/js/totop.js"></script><script src="/js/fancybox.pack.js"></script>
<script src="/js/jquery.fancybox.js"></script><link rel="stylesheet" href="/css/jquery.fancybox.css"><script>var duoshuoQuery = {short_name:'cyqluowang'};
(function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0]
        || document.getElementsByTagName('body')[0]).appendChild(ds);
})();
</script></div></body></html>